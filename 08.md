# Underflow and Denormal Values

Problems arise in computer maths when software has only a limited number of bits to express very, very large or very, very small values. When a value is too large to express in 80 bits (the largest common real-number format) that value “overflows” the number meant to receive it, and an error is generated. Less obviously, the reverse is possible: a value so small (that is, so close to 0) that it cannot be accurately expressed in 80 bits. This is called _underflow_. A special kind of number called a _denormal_ is used to express values resulting from underflows at lower precision, allowing them to be expressed in 80 bits, and used in further calculations without generating an error.

Later on, another reason for using coprocessors arose when customisable CPU architectures like those offered by ARM became popular. If the coprocessor is relatively independent of the CPU, it can be included or excluded from custom designs as needed.

### The ARM Coprocessor Interface

The ARM family of CPUs supports several different types of closely coupled coprocessors, including floating point, SIMD, and system control and cache maintenance. Modern transistor budgets have allowed all of these to be included on the same silicon with the CPU, sometimes as optional elements of custom designs. The ARM11 CPUs have a generalised coprocessor interface allowing as many as 16 coprocessors to cooperate with the CPU. The CPU uses a dedicated set of coprocessor interface instructions to communicate with coprocessors. Coprocessor instructions are compiled or assembled into the stored executable program file on disk or (in the Raspberry Pi) the SD card. They are part of the ordinary ARM instruction stream coming in from memory. They aren’t set apart in a separate memory area or specially treated by the ARM core.

Each coprocessor present in an ARM system has a unique 4-bit ID code. Coprocessor instructions contain a field for the ID code of the coprocessor on which they will execute. If the CPU core fetches a coprocessor instruction that doesn’t match the ID code of any existing coprocessor, it triggers an undefined instruction exception. (More on this shortly.)

One of the primary goals of the ARM coprocessor interface is not to slow down the CPU core. Beyond checking to see if a coprocessor instruction is coded for an existing coprocessor, the core does not spend time sorting out coprocessor instructions within its own pipeline. The core sends all the instructions it fetches from memory directly to all coprocessors. The coprocessor decodes all incoming instructions, which include both ordinary ARM instructions as well as coprocessor instructions. During the decoding stage, the coprocessor rejects any instructions that are not recognised as its own. This includes both ARM instructions and instructions coded for other coprocessors. The coprocessor recognises its own instructions, and adds only those to its internal execution pipeline. The coprocessor then sends a signal back to the core indicating that it has accepted an instruction.

The first-generation Raspberry Pi’s ARM1176JZF-S CPU includes two coprocessors—the System Control Coprocessor and the Vector Floating Point (VFP) coprocessor—which are described in the next sections.

### The System Control Coprocessor

The ARM11 System Control Coprocessor exposes a large suite of registers that are used to configure and control the operation of ARM core mechanisms like cache, direct memory access (DMA), the memory management unit (MMU), the TrustZone security system, exception handling and system performance, among others. Where tightly coupled memory (TCM) is present, it is managed by the system control coprocessor. (TCM is optional, and is not implemented in the Raspberry Pi’s BCM2835 silicon.)

Two ARM instructions handle communication with the system control coprocessor: the `MCR` instruction (from “move from coprocessor to register”) is used to read data from a coprocessor register; and the `MRC` instruction (from “move from register to coprocessor”) is used to write data from the core to a coprocessor register. `MCR` and `MRC` instructions can be used to communication with any coprocessor, but they represent the sole means of access to the system control coprocessor as it does not define any data processing operations of its own.

### The Vector Floating Point (VFP) Coprocessor

There are excellent reasons for gathering _floating point operations_ (that is, computer mathematics operating on fractional values) into a dedicated coprocessor. Floating point maths isn’t used much in a large number of software categories, but scientific and engineering applications, and games, use it a lot. CPUs designed for certain kinds of embedded systems work do not necessarily need a full maths coprocessor. Floating point operations, when required, can be implemented in library subroutines. Furthermore, floating point maths must be able to express values that have many significant figures, which requires registers larger than 32 bits to express.

The ARM11 core includes an extensive floating point maths coprocessor, the VFP11 Vector Floating Point Coprocessor. As with the ARM core itself, there is an ARM architecture for floating point machine instructions, which has evolved over time and has its own version numbering. VFP11 implements the VFPv2 instruction set architecture, which in turn implements a large subset of the IEEE 754 standard for binary floating point arithmetic. VFP11 is accessed by the ARM11 core through the ARM coprocessor interface, using two dedicated coprocessor numbers: 10 for single-precision instructions and 11 for double-precision instructions. Single precision as used in an ARM11 context means values represented in 32 bits. Double-precision values are represented in 64 bits.

The term _vector_ as used here denotes a one-dimensional array (that is, a series) of same-type data items. (There is more on arrays and other data structures in [Chapter 5](#08_9781119183938-ch05.xhtml).) This may sound familiar: vector maths is what SIMD instructions were designed to perform. The vector-processing features of VFP are relatively slow and limited and, starting with the Cortex group of ARM architectures, VFP vector maths has been deprecated in favour of the more powerful NEON SIMD coprocessor. (More on NEON later on, in connection with ARM Cortex.)

The VFP architecture provides single- and double-precision add, subtract, multiply, divide and square root operations, plus multiply-and-accumulate. This last is a specialised operation often used in digital signal processing (DSP). Given the importance of DSP in media software, optimised instructions for use in DSP work are a big win, performance-wise. Instructions are also provided for conversions between numeric types, and load/store instructions for moving floating point data directly between memory and VFP coprocessor registers. The VFPv2 architecture provides four banks of eight 32-bit registers. Two consecutive registers may be used to hold 64-bit double-precision values.

The IEEE 754 standard makes recommendations on how computer logic should implement transcendental functions (the exponential function, logarithms and trigonometry) but with VFPv2 these are not implemented in machine instructions and must be implemented as subroutines in libraries.

### Emulating Coprocessors

Nearly all architectures that support coprocessors provide a way to handle coprocessor instructions when the coprocessor in question isn’t present in a system. This is called _instruction emulation_. On the ARM processors, it’s handled by way of the undefined instruction exception.

Instruction emulation requires one subroutine in memory to perform the work of each emulated instruction. The core checks each coprocessor instruction that it fetches to see if the required coprocessor exists on the system. If not, the core triggers an undefined instruction exception. The exception handler contains a jump table with branches to emulation subroutines for all instructions coded for the missing coprocessor. The exception handler inspects the coprocessor instruction that triggered the exception, and branches to the appropriate emulation subroutine. The subroutine does the work that would ordinarily be done inside the coprocessor, and then returns control to the next instruction in the core pipeline.

Each instruction coded for a non-existent coprocessor triggers a separate exception into an emulation subroutine. As you might imagine, emulating a single-cycle instruction with a subroutine that might require dozens or hundreds of cycles is very slow. However, it’s certainly better than halting the current program.

## ARM Cortex

The ARM11 family was followed by a new group of ARM microarchitectures in 2006: Cortex. Unlike ARM11, which emcompassed only four cores based on the same microarchitecture, the Cortex brand encompasses many different core designs, each optimised for a particular application domain and area/performance/energy trade-off point. The Cortex processors fall into several categories called _profiles_, denoting broad emphasis:

- **Cortex-R:** Cores optimised for real-time embedded system service in automotive and industrial control devices - **Cortex-M:** Small, inexpensive, low-power cores optimised for use in microcontroller applications - **Cortex-A:** Cores optimised for use in devices like smartphones, tablets, e-book readers, digital TV appliances and other applications where a full operating system is necessary - **SecureCore:** Cores optimised for use in high-security financial and communication devices like ATMs, mass transit ticketing, pay-per-view media controllers, e-voting and ID systems

For space reasons, we’re confining this discussion to the A profile and sticking to the high points in the evolution of ARM CPUs.

### Multiple-Issue and Out-Of-Order Execution

The ARM11 core is a single-issue processor, which means that it loads one machine instruction into the pipeline at a time. The Cortex A8 introduced superscalar execution to ARM, and issues two instructions into its pipeline at once. This is often called dual issue. (See the “[Superscalar Execution](#07_9781119183938-ch04.xhtml#c04-sec-0017)” section earlier in this chapter.) The Cortex A9 core can issue two instructions at once, and the A15 three.

The Cortex A9 adds yet another performance trick new to ARM: out-of-order execution (OOE). In simple terms, OOE allows the CPU to determine when a machine instruction has to wait for its operands to be available and sets it aside until it’s ready to be issued to the execution units. Other instructions, taken from later in the instruction stream, can be issued during this time, provided their operands are available. When the operands of an instruction waiting in the dispatch queue arrive, the instruction is then issued to the pipeline.

Pre-OOE, the terms dispatch and issue meant the same thing: allowing an instruction to enter the execution pipeline. With OOE, an instruction can be dispatched to a queue after it’s been decoded, but the instruction is not issued to the execution units until its data is known to be available.

As you might expect, OOE requires yet more smarts (and lots more transistors) to avoid hazards and perform correctly. Before the instructions are retired, the CPU must ensure that OOE did not affect the results of the task being executed. This is a larger version of the challenge facing pipelined execution generally and superscalar execution in particular.

### Thumb 2

The Cortex A8 core introduced the Thumb 2 instruction set enhancements. In simplest terms, Thumb 2 augments the original 16-bit Thumb instruction set with a selection of 32-bit instructions, with the result that the Thumb 2 instruction set is nearly feature-equivalent to the full 32-bit ARM one, and the instruction-count penalty associated with Thumb is largely absent. Even with the new 32-bit instructions, 16-bit instructions can be used frequently enough to yield a useful increase in code density (especially on low-cost embedded systems with limited memory).

One shortcoming of the Thumb instruction set is the lack of conditional execution. Thumb 2 provides a partial fix for 16-bit Thumb instructions using the new `IT` (IF/THEN) instruction. `IT` provides a condition code that governs a block of up to four subsequent 16-bit instructions. Each instruction in the block can be tagged with either the condition code specified by the `IT` instruction or its complement, and it executes only if the condition is satisfied.

### Thumb EE

The Cortex A8 core introduced the Thumb-EE execution environment. Thumb-EE is an instruction architecture incorporating Thumb 2 instructions with features optimised for use with just-in-time (JIT) compilation of high-level languages like Java, Python, C# and Perl. Faster cores, larger memory spaces and better JIT compilers have made Jazelle and Thumb EE less necessary, and ARM Holdings deprecated Thumb EE in 2011.

### big.LITTLE

Power consumption is a critical issue in mobile computing, and much of the innovation in new ARM generations has gone to increasing performance without sacrificing ARM’s traditional advantage in energy efficiency. One technique introduced with the Cortex family goes by the trademark big.LITTLE. In devices implementing big.LITTLE there are two ARM cores (or clusters of cores) working together: a high-performance (out of order, multi-issue) core like the A15 that emphasises performance over energy per instruction, and a lower-performance (in order, single-issue) core like the A7 optimised for much lower energy used per instruction. The operating system can move individual processes between high- and low-energy cores on demand, and shut down unused cores, providing a much broader dynamic range in both processing capability and energy usage than would be available from a single mid-performance core.

The big.LITTLE technology was intended for use in custom SoC parts. The paired cores must be architecturally compatible and support multi-cluster cache coherence for the system to work. The A7/A15 pair was the first; the latest is the A53/A57 pair, which implements the new ARMv8 instruction set architecture.

### The NEON Coprocessor for SIMD

The Cortex family of processors introduced a major new coprocessor: NEON. Prior to the ARMv7 instruction set architecture, SIMD support on ARM was handled by ARMv6 instructions on the ARM core, and acted on four 8-bit quantities held in ARM general-purpose registers. NEON moves SIMD instruction execution out to the coprocessor, and adds more than 100 SIMD instructions to ARMv7. This removes dependence on ARM general-purpose registers, and allows a 128-bit wide SIMD-specific register set. Each of the 16 128-bit NEON registers is interpreted as containing multiple values of the same type. Four data types are supported:

- Sixteen 8-bit quantities - Eight 16-bit quantities - Four 32-bit quantities - Two 64-bit quantities

Which data type is used depends on the form of the SIMD machine instruction being executed. Underneath it all, the register is just a block of 128 bits. The instruction divides the source and destination registers into _lanes_, which are logical groupings of bits that are treated as separate quantities during SIMD maths (see Figure 4-21).

![[FIGURE 4-21:](#07_9781119183938-ch04.xhtml#rc04-fig-0021) How NEON SIMD lanes divide 128-bit registers into logical quantities](./media/images/9781119183938-fg0421.png)

The 16 128-bit registers may be accessed as 32 64-bit registers. If calculations don’t require lanes wider than 64 bits, this allows more calculations to be done in registers without additional load/store operations.

### ARMv8 and 64-Bit Computing

The Cortex family introduced the ARMv7 instruction set architecture. The new (at the time of writing) Cortex A50 family introduces a new ISA, ARMv8. The primary purpose of ARMv8 is to implement 64-bit computation and memory addressing for the ARM core family. In fact, ARMv8 provides three different instruction sets:

- **A32:** The 32-bit ARM instruction set, essentially unchanged from ARMv6 and ARMv7 - **T32:** The Thumb 2 instruction set, essentially unchanged from ARMv7 - **A64:** The new 64-bit instruction set

A64 makes significant changes to the Cortex architecture:

- The general-purpose registers are 64 bits wide instead of 32. - Machine instructions remain 32 bits in size to retain A32 code density. - Instructions may take either 32-bit or 64-bit operands. - The stack pointer and program counter are no longer general-purpose registers. - An improved exception mechanism makes banked registers unnecessary. - New optional instructions implement AES (Advanced Encryption Standard) encryption and both the SHA-1 and SHA-256 hashing algorithms in hardware. - New features support hardware-assisted virtual machine management.

The Raspberry Pi 3 computer, introduced in February 2016, incorporates an ARMv8 64-bit quad-core CPU. It is thus the first 64-bit Raspberry Pi.

## Systems on a Single Chip

It’s easier to describe the architecture of an Intel chip than an ARM-based chip, simply because there are so many more different varieties of the latter “in the wild”. ARM-based chips are custom jobs, in two senses:

- The CPU itself may be easily customised in terms of cache size, installed coprocessors and other significant features like TrustZone security. - The CPU very often shares silicon with peripherals like network controllers, graphics processors and even blocks of system memory, to form SoC devices.

Some ARM-based SoC parts (for example, the Apple A6X) are custom-designed and manufactured by a specific firm for its own mobile device products. Semiconductor manufacturers offer SoC parts of their own design to device manufacturers that don’t have the in-house resources to create a custom SoC from scratch.

### The Broadcom BCM2835 SoC

The first-generation Raspberry Pi computers are based on the BCM2835 SoC chip, designed and sold by Broadcom to manufacturers that want to field mobile devices like smartphones, tablets and e-book readers. The BCM2835 contains nearly all the digital logic necessary to create a standalone, graphics-intensive mobile computer. This logic falls into three broad categories:

- A single ARM core, the ARM1176JZF-S, licensed from ARM Holdings - A 1080p30-capable graphics processor, the VideoCore IV, developed and owned by Broadcom - 128KB of Level 2 cache, shared with the CPU but used primarily by the VideoCore IV processor - A suite of peripherals for the use of the ARM11 core, including: - An interrupt controller - Timers - A pulse-width modulator (PWM) - Two universal asynchronous receiver-transmitters (UARTs) - A general-purpose I/O (GPIO) system providing 54 I/O lines - An inter-IC sound (IIS or I2S) system and bus - A serial peripheral interface (SPI) master/slave bus mechanism

The BCM2835 does not contain system memory. As described in [Chapter 3](#06_9781119183938-ch03.xhtml), the single SDRAM memory device piggybacks on top of the BCM2835 device, using package-on-package (POP) ball-grid array (BGA) packaging.

### Broadcom’s Second- and Third-Generation SoC Devices

The Raspberry Pi 2’s release in February 2015 ushered in the second generation of Raspberry Pi computers. At the heart of the Raspberry Pi 2 is the BCM2836 SoC, which differs from the BCM2835 primarily in the CPU and Level 2 (L2) cache. The CPU is a quad-core ARM Cortex A-7 running at 900 MHz. Level 2 cache is 256KB, shared with the VideoCore IV graphics processor. The Raspberry Pi 2 board has 1 GB RAM, and the higher-capacity RAM IC is not mounted atop the SoC as in the Raspberry Pi 1 computers, but elsewhere on the printed circuit board.

The Raspberry Pi 3 computer, released in February 2016, is based on the BCM2837 SoC, again with a 1GB RAM IC mounted directly to the printed circuit board and not atop the SoC device itself. The BCM2837 contains a quad-core 64-bit ARM Cortex A-53 CPU, with 512KB shared L2 cache. The dual-core VideoCore IV processor now runs at 400 MHz (300 MHz for 3D graphics) rather than the 250 MHz of the earlier SoCs. Beyond that, it is almost identical to the original BCM2835.

### How VLSI Chips Happen

It’s beyond the scope of this book to explain very large scale integration (VLSI) semiconductor fabrication in detail, but some understanding is necessary so that the jargon and the design challenge make sense.

VLSI chips are fabricated with a photolithography process, which uses short-wavelength ultraviolet (UV) light and a set of photographic masks to chemically impose patterns on a silicon wafer. These patterns are applied in layers that eventually combine to form individual transistors, resistors, diodes and capacitors. People who have made their own printed circuits at home by etching away copper to form patterns of conductive traces on fibreglass boards will have a sense for what’s going on. The difference, of course, is that VLSI fabrication involves patterns that are mere nanometres (billionths of a metre) in size.

A single masking operation works like this:

1. A coating of a photosensitive chemical called _resist_ is applied to the wafer. 2. The mask is positioned over the wafer. 3. UV light is allowed to shine through the mask, hardening areas exposed to the UV. 4. The mask is removed, and the portions of the resist coating that were not exposed to UV are washed from the wafer. 5. A chemical process is applied to the wafer. Only where the unexposed resist was washed away can the chemicals reach the wafer. 6. The hardened resist is removed chemically in preparation for the next operation.

The chemical process in step 5 can be a number of things. An etchant may be applied to remove silicon. The wafer may be exposed to various chemicals for _doping_ the silicon—that is, infusing small quantities of elements like boron and phosphorus to alter the electrical properties of the silicon. This was originally done by exposing the wafer to dopant chemicals in gaseous or liquid form. These days, to achieve the precision required by increasingly smaller chip features, doping is often done by bombarding the wafer with dopant ions accelerated electromagnetically. Copper or some other metal (generally aluminium) may be applied to resist-free areas of the wafer, creating conductive paths.

Depending on the complexity of the integrated circuit (IC) being fabricated, there can be 20 or 30 separate masks, and as many as 50 masking steps. Masking must be done with a mind-boggling level of precision. If even one masking step is performed out of alignment, the entire wafer will be faulty and must be discarded.

### Processes, Geometries and Masks

The fabrication process described in the preceding section is a very touchy one. All the elements interact, and none can be changed without affecting the others. The sizes and shapes of the regions in the masks dictate the electrical properties of the silicon regions that the masks are used to create. At the sizes specified in modern IC designs, a difference of just a few million atoms in a P-N junction (a region where P-type and N-type semiconductor material are in contact, creating one or more transistors) can make the difference between a junction that works and one that works poorly or not at all. Leakage across junctions increases as the junction size decreases. Waste heat generated per unit area also increases as the sizes of the devices (transistors, resistors) decrease. All these factors must be taken into account.

For these reasons, it’s impossible to shrink an IC design just by optically shrinking the mask patterns used in fabrication. Creating a chip with smaller circuit elements means re-engineering the entire fabrication process from scratch. In fact, engineers use the word _process_ to mean a very specific sequence of steps that cannot be changed in any way. The defining parameter of a fabrication process is the size of the smallest components created on the silicon die. This is called the _process geometry_. At the time of writing, the cutting-edge geometry is 14 nanometres. To put this in perspective, the _lattice constant_ of silicon—the distance between silicon atoms on a smooth crystalline surface—is .54 nanometres. This means that a 14-nanometre feature on a silicon die is about 30 to 35 _atoms_ wide.

Because the size of the features drawn on a mask dictates their electrical properties, masks for fabricating a device are process and geometry specific.

### IP: Cells, Macrocells and Cores

Modern ICs, of whatever function, are almost never created from whole cloth. In other words, design engineers do not sit down at a CAD workstation and begin drawing individual transistors and other components. With hundreds of millions of devices on modern silicon dies, that would take a very long time. Fortunately, it’s also unnecessary.

Just as program code can be designed as a library of standard subroutines, digital logic expressed in silicon can be designed as libraries of standard cells. In a custom IC design context, a _cell_ is a single logic element (for example, a gate, an inverter, a flip-flop and so on) that has been laid out in mask form and verified for proper operation. Larger blocks of digital logic (registers, adders, memory blocks and so on) are called _macrocells_. When designers get to a subsystem level (processors, caches, coprocessors) the designs are generally called _cores_.

Libraries of standard cells and macrocells, along with complete and tested cores, are often sold by design houses and fabricators to groups wanting to create their own custom designs. The libraries and cores are licensed as intellectual property (IP), and IC design engineers idiomatically refer to any licensed digital logic block as “an IP”.

### Hard and Soft IP

Design houses sometimes license logic blocks that have already been tested and laid out for masks to be used in a specific fabrication process and geometry. These are called hard IPs, macrocells or cores, and are basically maps of polygons that may be integrated into CAD designs for process masks. Hard IPs are compact and reliable, but they can’t be used in processes other than the ones they were designed for.

Modern IPs are most often delivered as soft cores. These are descriptions of the logic and electrical behaviour of the IP, but not the physical layout on silicon. Soft IP is licensed in the form of source files written in a hardware description language (HDL) expressing the logic in an abstract form called register-transfer level (RTL). RTL is a way of describing hardware in terms of registers formed of flip-flops and combinatorial logic using simple logic gates. The description is of logic states transferred through clouds of flip-flops and gates, hence the term. RTL descriptions may be written in any of several HDLs, the most popular being Verilog and VHDL.

With a description of a design’s RTL logic written in an HDL, an IP may be synthesised to a matrix of individual gates called a netlist, and then placed (laid out in two dimensions) and routed (connected to one another) for a particular process. This essentially converts a soft IP to a hard IP, and is referred to as hardening an IP. Most IPs today are delivered as RTL files, and the synthesis and routing are done during the synthesis and routing of the SoC as a whole.

### Floorplanning, Layout and Routing

The actual physical creation of an SoC begins with a finished netlist that defines the entire device both logically and electrically. The challenge of creating SoC parts from a netlist lies in arranging cells and macrocells on a silicon die and connecting them as the netlist requires. Creating a tentative layout for an SoC is called _floorplanning_, and the metaphor is apt: engineers have to parcel out the area of a silicon die into regions big enough to hold all the parts of the design, just as architects divide the floor of a building into offices, lift-shafts, hallways and so on. Floorplanning must be done within a number of constraints:

- There is only so much area on the die. - Many macrocells (especially hard IPs licensed from design firms) have a fixed size, shape and orientation and thus no “wiggle room” for fitting into a layout. - There may be a maximum number of connection pads on the device package. - Some logic blocks (such as line drivers) must be physically close to the connection pads that they serve. - Data paths must not introduce timing problems or _crosstalk,_ which is electrical interference between adjacent conductors caused by capacitive or inductive effects.

Within such constraints, engineers strive to make the layout as small as possible, not only to maximise the number of devices per wafer, but also to minimise signal propagation delays. Floorplanning is a sort of intuitive “first cut” at a layout, to make the later job of the CAD software tools as easy as possible. With a floorplan in hand, engineers turn to placement, during which the precise position of elements in the layout is done using CAD tools. Placement may demand iterative changes in the floorplan, including the size and aspect ratio, which defines the proportions of the rectangle embracing the layout.

The final step is _routing_, which encompasses the crucial job of creating data paths, clock distribution paths and power distribution paths. Routing is where issues with crosstalk and capacitive coupling are actually modelled and the resulting timing violations (cases in which signals arrive at a flip-flop too late, or too soon) are corrected when found. Towards the end of the chip design process, the team enters what is termed the timing closure loop: violations are fixed by adjusting transistor sizes or inserting buffers, which in turn creates a (hopefully) smaller number of new violations, which are then fixed in turn until none remain. With routing finished for the desired process, the SoC design may be “taped out” (written to files in a final version) and sent to a chip foundry for mask creation and the eventual fabrication of “first silicon”.

### Standards for On-Chip Communication: AMBA

Integration of IP cores from multiple sources and the construction of a bus fabric to tie them together into a coherent whole comprise one of the most challenging steps in the design of any IC. The scale of the challenge grows with the complexity of the design, the clock rates at which it operates and the reduction of the size of the process geometry. Standards can help to simplify the design process by abstracting away the details of bus implementation, allowing IP cores and infrastructure components to be reused elsewhere on the chip, or in new projects.

In 1996, ARM Holdings introduced the Advanced Microcontroller Bus Architecture (AMBA) to do precisely that: provide standards for creating and reusing IP. ARM later released actual soft IP implementing AMBA-compliant on-chip data buses for SoCs. In the 20 years since its introduction, AMBA has gone through four generations; today it’s the de facto standard for on-chip buses, especially for SoCs that incorporate ARM processor cores. The AMBA standard is public and may be used without payment of royalties to ARM Holdings.

The AMBA spec includes several different bus architecture definitions, which are informally called _protocols_. Each protocol includes specs for both the physical connections between cores and the logic that governs data movement over the connections. The protocol used in the BCM2835 SoC is the Advanced Extensible Interface (AXI), which is part of the AMBA 3 specification. The version of AXI used in the Raspberry Pi is thus referred to as AXI 3. An AXI bus may be configured at design time to be from 8 to 1024 bits wide, in powers of two. The internal buses in the BCM2835 are between 32 and 256 bits wide, depending on the bandwidth required.

An AXI bus may be imagined (roughly) as an interconnected network of utility trenches dug between several buildings in a corporate campus. Builders lay pipes in the trenches to carry water, electricity, natural gas, wastewater or steam. The pipes are run side-by-side in the trenches but are not interconnected. An AXI bus incorporates five channels that carry data along paths on the SoC silicon, around and between the various cores on the SoC. Each channel is _unidirectional_, meaning that data passes only one way through the channel, just as water or natural gas flows only one way through the pipes that carry it. The flow of data over each bus is controlled using ready-valid signalling: the upstream end asserts (sets to high, or logic 1) a valid signal if it has data to transmit, the downstream end asserts a ready signal if it is able to accept data, and data is transferred during a clock cycle if, and only if, both signals are high.

Channels conduct data between two kinds of endpoints: master and slave. These are roughly equivalent to client and server in the network world. The master (which could, for example, be a CPU, graphics processor or video decode engine) requests a transaction, and the slave (which could be an SDRAM controller or a peripheral such as a UART) complies with the master’s request. The master may request either a data read or data write transaction, but in either case the transaction is requested and controlled by the master.

The five AXI3 channels are:

- **Read address channel:** Carries address and control information from a master to a slave endpoint that acts as a data source - **Read data channel:** Carries the requested data back from the slave to the master - **Write address channel:** Carries address and control information from a master to a slave endpoint that stores or otherwise uses data - **Write data channel:** Carries one or more pieces of data associated with a write address from the master to the slave that needs the data - **Write response channel:** Carries acknowledgment signals from the slave to the master, indicating that the data had been successfully received

Using these five channels, data may be moved very quickly around the bus (see Figure 4-22).

![[FIGURE 4-22:](#07_9781119183938-ch04.xhtml#rc04-fig-0022) AXI3 bus channels](./media/images/9781119183938-fg0422.png)

Three general types of bus component may be inserted into AXI3 channels:

- **Register slices:** “Latch” data moving through a bus channel into temporary memory. This allows timing conflicts to be resolved by breaking long paths into shorter ones. Metaphorically, a register slice is a way to place a “slice” of the bus onto a shelf, where it can wait until the other end of the channel signals the register slice that it can accept the slice data. Register slices can be combined to allow pipelining of data passing along the bus, in a way similar to how pipelining works for machine instructions in CPUs. - **Arbiters:** These merge multiple upstream buses into a single downstream bus. This allows multiple masters to interchange data with a single slave. The arbiter manages control information to ensure that the proper upstream bus receives read data and write responses intended for it. As an example, an arbiter is used to allow the ARM, the graphics processor and the video decode engine inside BCM2835 to share access to main memory. - **Splitters:** These divide a single upstream bus into multiple downstream buses. This allows a single master to exchange data with multiple slaves. As an example, a splitter is used to allow the ARM11 to access both main memory and the various peripherals on the SoC.

With these three components, an on-chip bus fabric can be made to connect the various cores making up an SoC in almost any useful combination. Much of the effort expended in designing an SoC is devoted to constructing a fabric that is capable of providing real-time masters, such as camera and display interfaces and video decode engines, with the bandwidth and latency quality-of-service (QoS) guarantees they require to meet specified performance goals. This in turn requires us to come up with policies that determine which port of an arbiter is granted access to the downstream bus if multiple upstream buses have pending requests, based on static information (the identity of the requesting master) and dynamic information (recent traffic history). QoS system design remains an active area of research in academic and commercial circles.
